{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":238205099,"sourceType":"kernelVersion"}],"dockerImageVersionId":31011,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-14T20:20:35.102618Z","iopub.execute_input":"2025-05-14T20:20:35.102808Z","iopub.status.idle":"2025-05-14T20:20:37.143260Z","shell.execute_reply.started":"2025-05-14T20:20:35.102792Z","shell.execute_reply":"2025-05-14T20:20:37.142579Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/notebook810eb1472d/_output_.zip\n/kaggle/input/notebook810eb1472d/__results__.html\n/kaggle/input/notebook810eb1472d/__notebook__.ipynb\n/kaggle/input/notebook810eb1472d/__output__.json\n/kaggle/input/notebook810eb1472d/custom.css\n/kaggle/input/notebook810eb1472d/__results___files/__results___2_0.jpg\n/kaggle/input/notebook810eb1472d/__results___files/__results___2_0.png\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import zipfile\nimport os\n\n# Path to the uploaded zip file\nzip_path = \"/kaggle/input/notebook810eb1472d/_output_.zip\"\nextract_path = \"/kaggle/working/frames\"\n\n# Unzip the file\nwith zipfile.ZipFile(zip_path, 'r') as zip_ref:\n    zip_ref.extractall(extract_path)\n\n# Check contents\nos.listdir(extract_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T20:20:37.143916Z","iopub.execute_input":"2025-05-14T20:20:37.144274Z","iopub.status.idle":"2025-05-14T20:22:20.256076Z","shell.execute_reply.started":"2025-05-14T20:20:37.144222Z","shell.execute_reply":"2025-05-14T20:22:20.255488Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"['__pycache__', 'combined_dataset.csv', 'frames']"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# import os\n# import time\n# import pandas as pd\n# import numpy as np\n# import torch\n# import torch.nn as nn\n# from torch.utils.data import Dataset, DataLoader\n# from torchvision import transforms\n# from PIL import Image\n# from sklearn.model_selection import train_test_split\n# from sklearn.preprocessing import StandardScaler\n# from sklearn.metrics import classification_report, confusion_matrix\n# from tqdm import tqdm\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import joblib\n\n# # -------------------------\n# # Configurations\n# # -------------------------\n# csv_path = \"/kaggle/working/frames/combined_dataset.csv\"\n# base_dir = \"/kaggle/working/split_data\"\n# os.makedirs(base_dir, exist_ok=True)\n# tabular_cols = ['EAR', 'MAR', 'Head_Tilt', 'Head_Nod']\n# batch_size = 32\n# epochs = 20\n# timeout_seconds = 11 * 3600 + 45 * 60\n# start_time = time.time()\n# timeout_reached = False\n\n# # -------------------------\n# # Load CSV & Clean\n# # -------------------------\n# df = pd.read_csv(csv_path)\n# df['img_path'] = df['img_path'].apply(lambda x: os.path.join(\"/kaggle/working/frames/frames\", os.path.basename(x)))\n# df['Label'] = df['Label'].map({0: 0, 5: 1, 10: 2})\n# df[tabular_cols] = df[tabular_cols].replace([np.inf, -np.inf], np.nan)\n# df = df.dropna(subset=tabular_cols).reset_index(drop=True)\n\n# scaler = StandardScaler()\n# df[tabular_cols] = scaler.fit_transform(df[tabular_cols])\n# joblib.dump(scaler, \"/kaggle/working/tabular_scaler.pkl\")  # Save scaler for later inference\n\n# # -------------------------\n# # Split Dataset & Save\n# # -------------------------\n# def save_split_data(split_df, name):\n#     folder = os.path.join(base_dir, name)\n#     os.makedirs(folder, exist_ok=True)\n#     split_df.to_csv(os.path.join(folder, \"dataset.csv\"), index=False)\n\n# train_val_df, test_df = train_test_split(df, test_size=0.15, stratify=df['Label'], random_state=42)\n# train_df, val_df = train_test_split(train_val_df, test_size=0.2, stratify=train_val_df['Label'], random_state=42)\n\n# save_split_data(train_df, \"train\")\n# save_split_data(val_df, \"val\")\n# save_split_data(test_df, \"test\")\n\n# # -------------------------\n# # Dataset Class\n# # -------------------------\n# class DrowsinessCombinedDataset(Dataset):\n#     def __init__(self, dataframe, transform=None):\n#         self.df = dataframe.reset_index(drop=True)\n#         self.transform = transform\n\n#     def __len__(self):\n#         return len(self.df)\n\n#     def __getitem__(self, idx):\n#         row = self.df.iloc[idx]\n#         image = Image.open(row['img_path']).convert('RGB')\n#         if self.transform:\n#             image = self.transform(image)\n#         tabular = torch.tensor(row[tabular_cols].astype(np.float32).values, dtype=torch.float32)\n#         label = torch.tensor(int(row['Label'])).long()\n#         return image, tabular, label\n\n# # -------------------------\n# # Transforms & Dataloaders\n# # -------------------------\n# transform = transforms.Compose([\n#     transforms.Resize((224, 224)),\n#     transforms.ToTensor(),\n#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n# ])\n\n# train_loader = DataLoader(DrowsinessCombinedDataset(train_df, transform), batch_size=batch_size, shuffle=True, num_workers=2)\n# val_loader = DataLoader(DrowsinessCombinedDataset(val_df, transform), batch_size=batch_size, num_workers=2)\n# test_loader = DataLoader(DrowsinessCombinedDataset(test_df, transform), batch_size=batch_size, num_workers=2)\n\n# # -------------------------\n# # Model Definition\n# # -------------------------\n# class DepthwiseSeparableConv(nn.Module):\n#     def __init__(self, in_channels, out_channels, stride=1):\n#         super().__init__()\n#         self.depthwise = nn.Conv2d(in_channels, in_channels, 3, stride, 1, groups=in_channels, bias=False)\n#         self.pointwise = nn.Conv2d(in_channels, out_channels, 1, bias=False)\n#         self.bn = nn.BatchNorm2d(out_channels)\n#         self.relu = nn.ReLU(inplace=True)\n\n#     def forward(self, x):\n#         x = self.depthwise(x)\n#         x = self.pointwise(x)\n#         x = self.bn(x)\n#         return self.relu(x)\n\n# class MobileNetWithTabularLSTM(nn.Module):\n#     def __init__(self, num_tabular_features, num_classes=3):\n#         super().__init__()\n#         self.cnn = nn.Sequential(\n#             nn.Conv2d(3, 32, 3, stride=2, padding=1, bias=False),\n#             nn.BatchNorm2d(32),\n#             nn.ReLU(inplace=True),\n#             DepthwiseSeparableConv(32, 64, 1),\n#             DepthwiseSeparableConv(64, 128, 2),\n#             DepthwiseSeparableConv(128, 128, 1),\n#             DepthwiseSeparableConv(128, 256, 2),\n#             DepthwiseSeparableConv(256, 256, 1),\n#             nn.AdaptiveAvgPool2d(1)\n#         )\n#         self.lstm = nn.LSTM(input_size=256, hidden_size=128, batch_first=True)\n#         self.fc = nn.Sequential(\n#             nn.Linear(128 + num_tabular_features, 128),\n#             nn.ReLU(),\n#             nn.Dropout(0.3),\n#             nn.Linear(128, num_classes)\n#         )\n\n#     def forward(self, image, tabular):\n#         x_img = self.cnn(image)\n#         x_img = torch.flatten(x_img, 1).unsqueeze(1)\n#         x_lstm, _ = self.lstm(x_img)\n#         x_lstm = x_lstm[:, -1, :]\n#         x = torch.cat([x_lstm, tabular], dim=1)\n#         return self.fc(x)\n\n# # -------------------------\n# # Training Setup\n# # -------------------------\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# model = MobileNetWithTabularLSTM(num_tabular_features=len(tabular_cols)).to(device)\n# criterion = nn.CrossEntropyLoss()\n# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n\n# checkpoint_path = \"/kaggle/working/checkpoint.pth\"\n# failsafe_model_path = \"/kaggle/working/failsafe_model.pth\"\n# best_model_path = \"/kaggle/working/best_model.pth\"\n# start_epoch = 0\n# best_val_acc = 0.0\n# train_accuracies, val_accuracies = [], []\n\n# # -------------------------\n# # Resume Checkpoint\n# # -------------------------\n# if os.path.exists(checkpoint_path):\n#     checkpoint = torch.load(checkpoint_path)\n#     model.load_state_dict(checkpoint['model_state_dict'])\n#     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n#     scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n#     start_epoch = checkpoint['epoch'] + 1\n#     best_val_acc = checkpoint['best_val_acc']\n#     print(f\"✅ Resumed from epoch {start_epoch}\")\n\n# # -------------------------\n# # Training Loop\n# # -------------------------\n# for epoch in range(start_epoch, epochs):\n#     model.train()\n#     correct, total, total_loss = 0, 0, 0\n#     for images, tabular, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n#         if time.time() - start_time >= timeout_seconds:\n#             timeout_reached = True\n#             torch.save(model.state_dict(), failsafe_model_path)\n#             print(\"⏰ Timeout reached. Saving failsafe model.\")\n#             break\n#         images, tabular, labels = images.to(device), tabular.to(device), labels.to(device)\n#         optimizer.zero_grad()\n#         outputs = model(images, tabular)\n#         loss = criterion(outputs, labels)\n#         loss.backward()\n#         optimizer.step()\n#         total_loss += loss.item()\n#         preds = outputs.argmax(1)\n#         correct += (preds == labels).sum().item()\n#         total += labels.size(0)\n\n#     if timeout_reached: break\n#     train_acc = 100 * correct / total\n#     train_accuracies.append(train_acc)\n#     print(f\"Train Loss: {total_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n\n#     model.eval()\n#     val_correct, val_total = 0, 0\n#     with torch.no_grad():\n#         for images, tabular, labels in val_loader:\n#             if time.time() - start_time >= timeout_seconds:\n#                 timeout_reached = True\n#                 torch.save(model.state_dict(), failsafe_model_path)\n#                 print(\"⏰ Timeout during validation.\")\n#                 break\n#             images, tabular, labels = images.to(device), tabular.to(device), labels.to(device)\n#             outputs = model(images, tabular)\n#             val_correct += (outputs.argmax(1) == labels).sum().item()\n#             val_total += labels.size(0)\n\n#     if timeout_reached: break\n#     val_acc = 100 * val_correct / val_total\n#     val_accuracies.append(val_acc)\n#     print(f\"Validation Accuracy: {val_acc:.2f}%\")\n\n#     scheduler.step()\n#     torch.save({\n#         'epoch': epoch,\n#         'model_state_dict': model.state_dict(),\n#         'optimizer_state_dict': optimizer.state_dict(),\n#         'scheduler_state_dict': scheduler.state_dict(),\n#         'best_val_acc': best_val_acc\n#     }, checkpoint_path)\n\n#     if val_acc > best_val_acc:\n#         best_val_acc = val_acc\n#         torch.save(model.state_dict(), best_model_path)\n#         print(\"✅ Best model saved.\")\n\n# # -------------------------\n# # Evaluation and Plots\n# # -------------------------\n# if not timeout_reached:\n#     model.load_state_dict(torch.load(best_model_path))\n#     model.eval()\n#     all_preds, all_labels = [], []\n#     with torch.no_grad():\n#         for images, tabular, labels in test_loader:\n#             images, tabular = images.to(device), tabular.to(device)\n#             outputs = model(images, tabular)\n#             all_preds.extend(outputs.argmax(1).cpu().numpy())\n#             all_labels.extend(labels.cpu().numpy())\n\n#     test_accuracy = 100 * np.mean(np.array(all_preds) == np.array(all_labels))\n#     print(\"\\n--- Test Set Performance ---\")\n#     print(classification_report(all_labels, all_preds, target_names=[\"Alert (0)\", \"Slightly Drowsy (1)\", \"Drowsy (2)\"]))\n#     print(f\"\\n✅ Test Accuracy: {test_accuracy:.2f}%\")\n\n#     cm = confusion_matrix(all_labels, all_preds)\n#     plt.figure(figsize=(6, 5))\n#     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Alert\", \"Slightly Drowsy\", \"Drowsy\"], yticklabels=[\"Alert\", \"Slightly Drowsy\", \"Drowsy\"])\n#     plt.xlabel(\"Predicted\")\n#     plt.ylabel(\"True\")\n#     plt.title(\"Confusion Matrix\")\n#     plt.savefig(\"/kaggle/working/confusion_matrix.png\")\n#     plt.show()\n\n#     plt.figure(figsize=(8, 5))\n#     plt.plot(range(start_epoch+1, epochs+1), train_accuracies, label='Train Accuracy')\n#     plt.plot(range(start_epoch+1, epochs+1), val_accuracies, label='Validation Accuracy')\n#     plt.xlabel('Epoch')\n#     plt.ylabel('Accuracy (%)')\n#     plt.title('Training vs Validation Accuracy')\n#     plt.legend()\n#     plt.grid(True)\n#     plt.savefig(\"/kaggle/working/accuracy_plot.png\")\n#     plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T20:05:36.372175Z","iopub.status.idle":"2025-05-14T20:05:36.372491Z","shell.execute_reply.started":"2025-05-14T20:05:36.372347Z","shell.execute_reply":"2025-05-14T20:05:36.372360Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, time, re\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport joblib\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# -------------------------\n# Configs\n# -------------------------\ncsv_path = \"/kaggle/working/frames/combined_dataset.csv\"\nframe_root = \"/kaggle/working/frames/frames\"\nbase_dir = \"/kaggle/working/split_data\"\nseq_len = 5\ntabular_cols = ['EAR', 'MAR', 'Head_Tilt', 'Head_Nod']\nbatch_size = 32\nepochs = 4\ntimeout_seconds = 11 * 3600 + 45 * 60\nstart_time = time.time()\ntimeout_reached = False\n\nos.makedirs(base_dir, exist_ok=True)\n\n# -------------------------\n# Load & Prepare Data\n# -------------------------\ndf = pd.read_csv(csv_path)\ndf['img_path'] = df['img_path'].apply(lambda x: os.path.join(frame_root, os.path.basename(x)))\ndf['Label'] = df['Label'].map({0: 0, 5: 1, 10: 2})\ndf[tabular_cols] = df[tabular_cols].replace([np.inf, -np.inf], np.nan)\ndf = df.dropna(subset=tabular_cols).reset_index(drop=True)\n\n# Extract video_id and frame_number\ndef extract_metadata(path):\n    match = re.search(r\"/frames/(.+?)/frame_(\\d+)\", path)\n    if match:\n        return match.group(1), int(match.group(2))\n    return \"unknown\", -1\n\ndf[['video_id', 'frame_number']] = df['img_path'].apply(lambda x: pd.Series(extract_metadata(x)))\n\n# Normalize tabular features\nscaler = StandardScaler()\ndf[tabular_cols] = scaler.fit_transform(df[tabular_cols])\njoblib.dump(scaler, \"/kaggle/working/tabular_scaler.pkl\")\n\n# -------------------------\n# Build Sequences\n# -------------------------\ndf = df.sort_values(['video_id', 'frame_number'])\n\nsequence_data = []\nfor _, group in df.groupby('video_id'):\n    group = group.reset_index(drop=True)\n    for i in range(len(group) - seq_len + 1):\n        window = group.iloc[i:i+seq_len]\n        if len(window['Label'].unique()) == 1:\n            sequence_data.append({\n                'img_paths': window['img_path'].tolist(),\n                'tabular': window[tabular_cols].values,\n                'label': window['Label'].iloc[0]\n            })\n\nseq_df = pd.DataFrame(sequence_data)\ntrain_val_df, test_df = train_test_split(seq_df, test_size=0.15, stratify=seq_df['label'], random_state=42)\ntrain_df, val_df = train_test_split(train_val_df, test_size=0.2, stratify=train_val_df['label'], random_state=42)\n\n# -------------------------\n# Dataset & Dataloader\n# -------------------------\nclass DrowsinessSequenceDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.df = dataframe\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        item = self.df.iloc[idx]\n        images = [Image.open(p).convert(\"RGB\") for p in item['img_paths']]\n        if self.transform:\n            images = [self.transform(img) for img in images]\n        images = torch.stack(images)\n        tabular = torch.tensor(item['tabular'], dtype=torch.float32)\n        label = torch.tensor(item['label'], dtype=torch.long)\n        return images, tabular, label\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ntrain_loader = DataLoader(DrowsinessSequenceDataset(train_df, transform), batch_size=batch_size, shuffle=True, num_workers=2)\nval_loader = DataLoader(DrowsinessSequenceDataset(val_df, transform), batch_size=batch_size, num_workers=2)\ntest_loader = DataLoader(DrowsinessSequenceDataset(test_df, transform), batch_size=batch_size, num_workers=2)\n\n# -------------------------\n# Model\n# -------------------------\nclass DepthwiseSeparableConv(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super().__init__()\n        self.depthwise = nn.Conv2d(in_channels, in_channels, 3, stride, 1, groups=in_channels, bias=False)\n        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, bias=False)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        x = self.depthwise(x)\n        x = self.pointwise(x)\n        x = self.bn(x)\n        return self.relu(x)\n\nclass MobileNetSequenceModel(nn.Module):\n    def __init__(self, num_tabular_features, num_classes=3):\n        super().__init__()\n        self.cnn = nn.Sequential(\n            nn.Conv2d(3, 32, 3, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            DepthwiseSeparableConv(32, 64),\n            DepthwiseSeparableConv(64, 128, 2),\n            DepthwiseSeparableConv(128, 128),\n            DepthwiseSeparableConv(128, 256, 2),\n            DepthwiseSeparableConv(256, 256),\n            nn.AdaptiveAvgPool2d(1)\n        )\n        self.lstm = nn.LSTM(input_size=256 + num_tabular_features, hidden_size=128, batch_first=True)\n        self.fc = nn.Sequential(\n            nn.Linear(128, 128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, num_classes)\n        )\n\n    def forward(self, images, tabular):\n        B, S, C, H, W = images.shape\n        images = images.view(B*S, C, H, W)\n        features = self.cnn(images).view(B, S, -1)\n        x = torch.cat([features, tabular], dim=2)\n        lstm_out, _ = self.lstm(x)\n        return self.fc(lstm_out[:, -1])\n\n# -------------------------\n# Train Setup\n# -------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = MobileNetSequenceModel(num_tabular_features=len(tabular_cols)).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n\ncheckpoint_path = \"/kaggle/working/checkpoint.pth\"\nfailsafe_model_path = \"/kaggle/working/failsafe_model.pth\"\nbest_model_path = \"/kaggle/working/best_model.pth\"\nstart_epoch = 0\nbest_val_acc = 0.0\ntrain_accuracies, val_accuracies = [], []\n\nif os.path.exists(checkpoint_path):\n    checkpoint = torch.load(checkpoint_path)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n    start_epoch = checkpoint['epoch'] + 1\n    best_val_acc = checkpoint['best_val_acc']\n    print(f\"✅ Resumed from epoch {start_epoch}\")\n\n# -------------------------\n# Train Loop with ETA\n# -------------------------\nfor epoch in range(start_epoch, epochs):\n    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n    model.train()\n    correct, total, total_loss = 0, 0, 0\n\n    progress_bar = tqdm(train_loader, desc=f\"Train Epoch {epoch+1}\", ncols=100)\n    for batch_idx, (images, tabular, labels) in enumerate(progress_bar, 1):\n        if time.time() - start_time >= timeout_seconds:\n            torch.save(model.state_dict(), failsafe_model_path)\n            print(\"⏰ Timeout. Saved failsafe model.\")\n            timeout_reached = True\n            break\n\n        images, tabular, labels = images.to(device), tabular.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images, tabular)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        preds = outputs.argmax(1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n        total_loss += loss.item()\n\n        batch_acc = 100 * (preds == labels).sum().item() / labels.size(0)\n        epoch_acc = 100 * correct / (total if total > 0 else 1)\n\n        progress_bar.set_postfix({\n            'Loss': f'{loss.item():.4f}',\n            'Batch Acc': f'{batch_acc:.2f}%',\n            'Epoch Acc': f'{epoch_acc:.2f}%'\n        })\n\n    if timeout_reached:\n        break\n\n    train_acc = 100 * correct / total\n    train_accuracies.append(train_acc)\n    print(f\"\\n✅ Train Loss: {total_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n\n    model.eval()\n    val_correct, val_total = 0, 0\n    with torch.no_grad():\n        for images, tabular, labels in val_loader:\n            images, tabular, labels = images.to(device), tabular.to(device), labels.to(device)\n            outputs = model(images, tabular)\n            preds = outputs.argmax(1)\n            val_correct += (preds == labels).sum().item()\n            val_total += labels.size(0)\n\n    val_acc = 100 * val_correct / val_total\n    val_accuracies.append(val_acc)\n    print(f\"📊 Validation Accuracy: {val_acc:.2f}%\")\n\n    scheduler.step()\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'scheduler_state_dict': scheduler.state_dict(),\n        'best_val_acc': best_val_acc\n    }, checkpoint_path)\n\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save(model.state_dict(), best_model_path)\n        print(\"💾 Best model saved.\")\n\n# -------------------------\n# Final Evaluation\n# -------------------------\nif not timeout_reached:\n    model.load_state_dict(torch.load(best_model_path))\n    model.eval()\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for images, tabular, labels in test_loader:\n            images, tabular = images.to(device), tabular.to(device)\n            outputs = model(images, tabular)\n            all_preds.extend(outputs.argmax(1).cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    print(\"\\n--- Test Set Performance ---\")\n    print(classification_report(all_labels, all_preds, target_names=[\"Alert\", \"Slightly Drowsy\", \"Drowsy\"]))\n    print(f\"✅ Test Accuracy: {np.mean(np.array(all_preds) == np.array(all_labels)) * 100:.2f}%\")\n\n    cm = confusion_matrix(all_labels, all_preds)\n    plt.figure(figsize=(6, 5))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Alert\", \"Slightly Drowsy\", \"Drowsy\"], yticklabels=[\"Alert\", \"Slightly Drowsy\", \"Drowsy\"])\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.title(\"Confusion Matrix\")\n    plt.savefig(\"/kaggle/working/confusion_matrix.png\")\n    plt.show()\n\n    plt.figure(figsize=(8, 5))\n    plt.plot(range(start_epoch+1, epochs+1), train_accuracies, label='Train Accuracy')\n    plt.plot(range(start_epoch+1, epochs+1), val_accuracies, label='Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.title('Training vs Validation Accuracy')\n    plt.legend()\n    plt.grid(True)\n    plt.savefig(\"/kaggle/working/accuracy_plot.png\")\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T20:22:42.241079Z","iopub.execute_input":"2025-05-14T20:22:42.241360Z","iopub.status.idle":"2025-05-15T03:38:14.829495Z","shell.execute_reply.started":"2025-05-14T20:22:42.241339Z","shell.execute_reply":"2025-05-15T03:38:14.827575Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/6\n","output_type":"stream"},{"name":"stderr","text":"Train Epoch 1: 100%|█| 16236/16236 [1:29:54<00:00,  3.01it/s, Loss=0.5229, Batch Acc=79.31%, Epoch A","output_type":"stream"},{"name":"stdout","text":"\n✅ Train Loss: 11342.0216, Train Accuracy: 64.36%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"📊 Validation Accuracy: 79.23%\n💾 Best model saved.\n\nEpoch 2/6\n","output_type":"stream"},{"name":"stderr","text":"Train Epoch 2: 100%|█| 16236/16236 [1:28:45<00:00,  3.05it/s, Loss=0.3010, Batch Acc=82.76%, Epoch A","output_type":"stream"},{"name":"stdout","text":"\n✅ Train Loss: 6729.4458, Train Accuracy: 81.64%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"📊 Validation Accuracy: 85.84%\n💾 Best model saved.\n\nEpoch 3/6\n","output_type":"stream"},{"name":"stderr","text":"Train Epoch 3: 100%|█| 16236/16236 [1:28:31<00:00,  3.06it/s, Loss=0.2234, Batch Acc=96.55%, Epoch A","output_type":"stream"},{"name":"stdout","text":"\n✅ Train Loss: 5252.9172, Train Accuracy: 86.17%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"📊 Validation Accuracy: 87.88%\n💾 Best model saved.\n\nEpoch 4/6\n","output_type":"stream"},{"name":"stderr","text":"Train Epoch 4: 100%|█| 16236/16236 [1:30:45<00:00,  2.98it/s, Loss=0.2906, Batch Acc=86.21%, Epoch A","output_type":"stream"},{"name":"stdout","text":"\n✅ Train Loss: 4521.9855, Train Accuracy: 88.27%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/1610446243.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0mval_correct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtabular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtabular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtabular\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtabular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"model.load_state_dict(torch.load(best_model_path))\n    model.eval()\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for images, tabular, labels in test_loader:\n            images, tabular = images.to(device), tabular.to(device)\n            outputs = model(images, tabular)\n            all_preds.extend(outputs.argmax(1).cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    print(\"\\n--- Test Set Performance ---\")\n    print(classification_report(all_labels, all_preds, target_names=[\"Alert\", \"Slightly Drowsy\", \"Drowsy\"]))\n    print(f\"✅ Test Accuracy: {np.mean(np.array(all_preds) == np.array(all_labels)) * 100:.2f}%\")\n\n    cm = confusion_matrix(all_labels, all_preds)\n    plt.figure(figsize=(6, 5))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Alert\", \"Slightly Drowsy\", \"Drowsy\"], yticklabels=[\"Alert\", \"Slightly Drowsy\", \"Drowsy\"])\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.title(\"Confusion Matrix\")\n    plt.savefig(\"/kaggle/working/confusion_matrix.png\")\n    plt.show()\n\n    plt.figure(figsize=(8, 5))\n    plt.plot(range(start_epoch+1, epochs+1), train_accuracies, label='Train Accuracy')\n    plt.plot(range(start_epoch+1, epochs+1), val_accuracies, label='Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.title('Training vs Validation Accuracy')\n    plt.legend()\n    plt.grid(True)\n    plt.savefig(\"/kaggle/working/accuracy_plot.png\")\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T03:38:15.284439Z","iopub.execute_input":"2025-05-15T03:38:15.284966Z","iopub.status.idle":"2025-05-15T03:38:15.292097Z","shell.execute_reply.started":"2025-05-15T03:38:15.284937Z","shell.execute_reply":"2025-05-15T03:38:15.291255Z"}},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_31/1286434559.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    model.eval()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"],"ename":"IndentationError","evalue":"unexpected indent (1286434559.py, line 2)","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}