{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":238205099,"sourceType":"kernelVersion"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-14T19:12:19.904193Z","iopub.execute_input":"2025-05-14T19:12:19.904418Z","iopub.status.idle":"2025-05-14T19:12:21.219894Z","shell.execute_reply.started":"2025-05-14T19:12:19.904393Z","shell.execute_reply":"2025-05-14T19:12:21.219045Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/notebook810eb1472d/_output_.zip\n/kaggle/input/notebook810eb1472d/__results__.html\n/kaggle/input/notebook810eb1472d/__notebook__.ipynb\n/kaggle/input/notebook810eb1472d/__output__.json\n/kaggle/input/notebook810eb1472d/custom.css\n/kaggle/input/notebook810eb1472d/__results___files/__results___2_0.jpg\n/kaggle/input/notebook810eb1472d/__results___files/__results___2_0.png\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import zipfile\nimport os\n\n# Path to the uploaded zip file\nzip_path = \"/kaggle/input/notebook810eb1472d/_output_.zip\"\nextract_path = \"/kaggle/working/frames\"\n\n# Unzip the file\nwith zipfile.ZipFile(zip_path, 'r') as zip_ref:\n    zip_ref.extractall(extract_path)\n\n# Check contents\nos.listdir(extract_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T19:12:21.221615Z","iopub.execute_input":"2025-05-14T19:12:21.221926Z","iopub.status.idle":"2025-05-14T19:14:06.681107Z","shell.execute_reply.started":"2025-05-14T19:12:21.221908Z","shell.execute_reply":"2025-05-14T19:14:06.680413Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"['combined_dataset.csv', '__pycache__', 'frames']"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import os\nimport time\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\n# -------------------------\n# Load CSV & Clean\n# -------------------------\ncsv_path = \"/kaggle/working/frames/combined_dataset.csv\"\ndf = pd.read_csv(csv_path)\n\ndf['img_path'] = df['img_path'].apply(lambda x: os.path.join(\"/kaggle/working/frames/frames\", os.path.basename(x)))\ndf['Label'] = df['Label'].map({0: 0, 5: 1, 10: 2})\n\ntabular_cols = ['EAR', 'MAR', 'Head_Tilt', 'Head_Nod']\ndf[tabular_cols] = df[tabular_cols].replace([np.inf, -np.inf], np.nan)\ndf = df.dropna(subset=tabular_cols).reset_index(drop=True)\n\nscaler = StandardScaler()\ndf[tabular_cols] = scaler.fit_transform(df[tabular_cols])\n\n# -------------------------\n# Split Dataset\n# -------------------------\ntrain_val_df, test_df = train_test_split(df, test_size=0.15, stratify=df['Label'], random_state=42)\ntrain_df, val_df = train_test_split(train_val_df, test_size=0.2, stratify=train_val_df['Label'], random_state=42)\n\n# -------------------------\n# Dataset Class\n# -------------------------\nclass DrowsinessCombinedDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.df = dataframe.reset_index(drop=True)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        image = Image.open(row['img_path']).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        tabular = torch.tensor(row[tabular_cols].astype(np.float32).values, dtype=torch.float32)\n        label = torch.tensor(int(row['Label'])).long()\n        return image, tabular, label\n\n# -------------------------\n# Transforms and DataLoaders\n# -------------------------\ntransform = transforms.Compose([\n    transforms.Resize((240, 240)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(20),\n    transforms.RandomApply([transforms.GaussianBlur(5)], p=0.2),\n    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.3),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ntrain_loader = DataLoader(DrowsinessCombinedDataset(train_df, transform), batch_size=32, shuffle=True, num_workers=2, drop_last=True)\n\nval_loader = DataLoader(DrowsinessCombinedDataset(val_df, transform), batch_size=32, shuffle=False, num_workers=2)\ntest_loader = DataLoader(DrowsinessCombinedDataset(test_df, transform), batch_size=32, shuffle=False, num_workers=2)\n\n# -------------------------\n# Model Class with EfficientNetB1 and BiLSTM\n# -------------------------\n# -------------------------\n# Model Class with EfficientNetB1 and BiLSTM\n# -------------------------\nclass EfficientNetWithTabularBiLSTM(nn.Module):\n    def __init__(self, num_tabular_features, num_classes=3):\n        super(EfficientNetWithTabularBiLSTM, self).__init__()\n        self.efficientnet = models.efficientnet_b1(weights=models.EfficientNet_B1_Weights.DEFAULT)\n        self.efficientnet = nn.Sequential(*list(self.efficientnet.children())[:-1])\n        self.efficientnet_fc_input_dim = 1280\n        self.lstm_input_size = self.efficientnet_fc_input_dim + num_tabular_features\n        self.bilstm = nn.LSTM(input_size=self.lstm_input_size, hidden_size=128, num_layers=2, batch_first=True, bidirectional=True)\n        self.fc = nn.Sequential(\n            nn.Linear(256, 128),\n            nn.BatchNorm1d(128), \n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.Linear(128, num_classes)\n        )\n\n    def forward(self, image, tabular):\n        x_img = self.efficientnet(image)\n        x_img = torch.flatten(x_img, 1)\n        x_combined = torch.cat([x_img, tabular], dim=1).unsqueeze(1)\n        x_lstm, _ = self.bilstm(x_combined)\n        x_lstm = x_lstm[:, -1, :]\n        \n        # Batch normalization issue when batch size is 1\n        if x_lstm.size(0) == 1:\n            x_lstm = self.fc[0](x_lstm)  # Linear\n            x_lstm = x_lstm.unsqueeze(0) if x_lstm.dim() == 1 else x_lstm\n            if x_lstm.size(0) > 1:\n                x_lstm = self.fc[1](x_lstm)  # BatchNorm1d\n            x_lstm = self.fc[2](x_lstm)  # ReLU\n            x_lstm = self.fc[3](x_lstm)  # Dropout\n            x_lstm = self.fc[4](x_lstm)  # Final Linear\n            return x_lstm.squeeze(0)\n\n        # General case for batch size > 1\n        x_lstm = self.fc(x_lstm)\n        return x_lstm\n\n\n\n\n# -------------------------\n# Training and Evaluation\n# -------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = EfficientNetWithTabularBiLSTM(num_tabular_features=4).to(device)\ncriterion = nn.CrossEntropyLoss(label_smoothing=0.1)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\nearly_stopping_patience = 5\n\nnum_epochs = 10\nbest_val_acc = 0\npatience_counter = 0\n\ntrain_accuracies = []\nval_accuracies = []\n\nbest_val_acc = 0  # Track the best validation accuracy\n\nfor epoch in range(num_epochs):\n    model.train()\n    correct, total, total_loss = 0, 0, 0\n    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n    for images, tabular, labels in pbar:\n        images, tabular, labels = images.to(device), tabular.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images, tabular)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n\n        batch_acc = 100. * correct / total\n        pbar.set_postfix(loss=total_loss/(total+1), accuracy=batch_acc)\n\n    train_acc = 100. * correct / total\n    train_accuracies.append(train_acc)\n\n    # Validation phase\n    model.eval()\n    correct, total = 0, 0\n    with torch.no_grad():\n        for images, tabular, labels in val_loader:\n            images, tabular, labels = images.to(device), tabular.to(device), labels.to(device)\n            outputs = model(images, tabular)\n            _, predicted = outputs.max(1)\n            correct += predicted.eq(labels).sum().item()\n            total += labels.size(0)\n\n    val_acc = 100. * correct / total\n    val_accuracies.append(val_acc)\n    scheduler.step(total_loss)\n\n    # Check if the current validation accuracy is the best\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save(model.state_dict(), \"best_model.pth\")\n        print(f\"New best model saved with accuracy: {best_val_acc:.2f}%\")\n\n    print(f\"Epoch {epoch+1}/{num_epochs} - Train Accuracy: {train_acc:.2f}% - Validation Accuracy: {val_acc:.2f}%\")\n\nprint(\"Training Complete. Best Validation Accuracy:\", max(val_accuracies))\n\nplt.plot(train_accuracies, label='Train Accuracy')\nplt.plot(val_accuracies, label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy (%)')\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T21:45:16.066280Z","iopub.execute_input":"2025-05-14T21:45:16.067119Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/5: 100%|██████████| 16247/16247 [1:00:10<00:00,  4.50it/s, accuracy=62.7, loss=0.026]\n","output_type":"stream"},{"name":"stdout","text":"New best model saved with accuracy: 74.76%\nEpoch 1/5 - Train Accuracy: 62.69% - Validation Accuracy: 74.76%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|██████████| 16247/16247 [1:00:34<00:00,  4.47it/s, accuracy=74.9, loss=0.0217]\n","output_type":"stream"},{"name":"stdout","text":"New best model saved with accuracy: 78.58%\nEpoch 2/5 - Train Accuracy: 74.93% - Validation Accuracy: 78.58%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|██████████| 16247/16247 [1:00:40<00:00,  4.46it/s, accuracy=78, loss=0.0204] \n","output_type":"stream"},{"name":"stdout","text":"New best model saved with accuracy: 81.03%\nEpoch 3/5 - Train Accuracy: 78.03% - Validation Accuracy: 81.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|██████████| 16247/16247 [57:40<00:00,  4.70it/s, accuracy=79.8, loss=0.0197] \n","output_type":"stream"},{"name":"stdout","text":"New best model saved with accuracy: 82.11%\nEpoch 4/5 - Train Accuracy: 79.82% - Validation Accuracy: 82.11%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|██████████| 16247/16247 [1:02:31<00:00,  4.33it/s, accuracy=81.2, loss=0.0191]\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}